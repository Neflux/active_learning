{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, warnings, json, glob, tables\n",
    "from pathlib import Path\n",
    "path = str(Path(os.path.join('..','src','elohim','elohim')).resolve())\n",
    "if path not in sys.path:\n",
    "    sys.path.insert(0,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading lastly recorded simulation instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, glob, re\n",
    "import numpy as np\n",
    "ds = [d for d in sorted(os.scandir(os.path.join('..','history')), key=lambda x:x.path, reverse=False) if re.match(r'(.*?)[0-9]{4}-[0-9]{6}', d.path) is not None]\n",
    "print([d.path for d in ds])\n",
    "d = ds[-1]\n",
    "print(f'The most recent simulation folder has been selected \"{d.path}\":')\n",
    "points_file = os.path.join(d.path, 'points.json')\n",
    "assert os.path.exists(points_file)\n",
    "with open(points_file) as f:\n",
    "    points = json.load(f)\n",
    "targets = np.array([[t[\"x\"], t[\"y\"]] for t in points[\"targets\"]])\n",
    "fp_files = glob.glob(f'{d.path}/*.h5')\n",
    "files = [os.path.basename(x) for x in fp_files]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the obstacles coordinates in this specific simulation instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "points_file = os.path.join(d.path, 'points.json')\n",
    "with open(points_file) as f:\n",
    "    points_d = json.load(f)\n",
    "targets = np.array([[t[\"x\"], t[\"y\"]] for t in points_d[\"targets\"]])\n",
    "spawn_coords = np.array([[t[\"x\"], t[\"y\"]] for t in points_d[\"spawn_coords\"]])\n",
    "fig, ax = plt.subplots(figsize=(5,5),dpi=300)\n",
    "ax.plot(*targets.T, 'o', c='red',ms=1, label='Obstacle')\n",
    "ax.plot(*spawn_coords.T, 'o', ms=4, label='Spawn point')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y',rotation=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend()\n",
    "ax.set_title('Map arrangment for training')\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_map_1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move everything from hdf5 to pandas, while taking the necessary precaution in case the custom rosbag was still appending data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, time\n",
    "import pandas as pd, tables\n",
    "\n",
    "assert len(files) >= 4\n",
    "print('Preparing dataset..', end=' ')\n",
    "last_snapshot = {}\n",
    "while len(last_snapshot) == 0:\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=tables.PerformanceWarning)\n",
    "            last_snapshot = {}\n",
    "            for ff in fp_files:\n",
    "                last_snapshot[ff] = pd.read_hdf(ff)\n",
    "                print(last_snapshot[ff].columns)\n",
    "    except ValueError:\n",
    "        print(f'No dataset in HDF5 file: {ff}')\n",
    "        exit()\n",
    "    except Exception:\n",
    "        print(\"Recorder is probably locking the file, trying again in 3 second\")\n",
    "        time.sleep(3)\n",
    "print('Done')\n",
    "display(pd.concat([last_snapshot[i].head(1).reset_index(drop=True) for i in fp_files], axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's merge dataframes of data from different sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analyzer, importlib\n",
    "from analyzer import mergedfs\n",
    "importlib.reload(analyzer)\n",
    "df = mergedfs(last_snapshot)\n",
    "print(f'Unique runs: {len(df[\"run\"].unique())}')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before starting to process data, we need a quick tool to visually check any particular simulation run that shows odd statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, let's use the camera feed, imshow funcanim should be quick enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import animation\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from fractions import Fraction\n",
    "import pathlib\n",
    "from IPython.display import Video\n",
    "import config\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import cv_from_binary\n",
    "\n",
    "def show_camera_feed(df, target='run', run_id=None, big_run_id=None, folder=None, rate=30, s=None):\n",
    "\n",
    "    if run_id is not None:\n",
    "        data = df[df['run'] == run_id][['image',target]].copy()\n",
    "    if big_run_id is not None:\n",
    "        data = df[df['big_block'] == big_run_id][['image',target]].copy()\n",
    "    else:\n",
    "        data = df[['image',target]].copy()\n",
    "        \n",
    "    if s is not None:\n",
    "        data = data.iloc[s]\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        print('empty')\n",
    "        return\n",
    "    Writer = animation.writers['ffmpeg']\n",
    "    writer = Writer(fps=rate, metadata=dict(artist='Me'), bitrate=1800)\n",
    "    images = data['image'].map(cv_from_binary).map(Image.fromarray, \"RGB\").values\n",
    "    \n",
    "    matplotlib.rcParams['animation.embed_limit'] = images.nbytes * 13215\n",
    "    frac = Fraction(*config.camera_shape[:2][::-1])\n",
    "    fig, ax = plt.subplots(figsize=(frac.numerator*2,frac.denominator*2))\n",
    "    ax.axis('off')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "    feed_frame = ax.imshow(images[0])\n",
    "    \n",
    "    sensor_data = data[target].round(3).astype(str).values\n",
    "    sensor = ax.text(0.1,0.1, s=sensor_data[0], weight='bold', color='white', size=25, transform=ax.transAxes)\n",
    "    def init():\n",
    "        feed_frame.set_data(images[0])\n",
    "        sensor.set_text(sensor_data[0])\n",
    "        return feed_frame, sensor,\n",
    "    def animate(i):\n",
    "        feed_frame.set_data(images[i])\n",
    "        sensor.set_text(sensor_data[i])\n",
    "        return feed_frame, sensor,\n",
    "    ani = FuncAnimation(fig, animate, frames=len(images), interval=1000. / rate, blit=True, init_func=init, repeat=True)\n",
    "    plt.close()\n",
    "    \n",
    "    if folder is None:\n",
    "        folder = '.'\n",
    "    folder = os.path.join(folder, 'single_runs')\n",
    "    pathlib.Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    file_path = os.path.join(folder,f'run_{str(run_id).zfill(3)}.mp4')\n",
    "    ani.save(file_path, writer=writer, progress_callback=lambda i, n: print(f'\\rProgress: {(i+1) * 100. / n:.2f} %', end=''))\n",
    "    print(f'\\rComplete! Video file saved to {file_path}')\n",
    "    return Video(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 500\n",
    "a = np.random.randint(len(df)-size)\n",
    "show_camera_feed(df.iloc[a:a+size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_big_runs(df):\n",
    "    df = df.copy()\n",
    "    out_of_map = (df[['ground_truth_odom_x','ground_truth_odom_y']].abs() > 10).any(axis=1)\n",
    "    df['big_block'] = (out_of_map != out_of_map.shift(1)).cumsum().astype(int)\n",
    "    df = df[~out_of_map]\n",
    "    df['big_block'] = (df['big_block'] != df['big_block'].shift(1)).cumsum().astype(int)\n",
    "    #df.groupby('big_block').apply(lambda x: display(x))\n",
    "    print(df['big_block'].unique())\n",
    "    return df\n",
    "df = extract_big_runs(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe let's remove the -1 save iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['run'] == -1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_camera_feed(df, big_run_id=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import config\n",
    "# df['obstacle_near'] = df['sensor'] != config.max_sensor_threshold\n",
    "# display(df['sensor'].min())\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove all runs that are too short to even build a single occupancy map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import config\n",
    "\n",
    "# window = '20s'\n",
    "# df = df.groupby('run').filter(lambda x: (x.index[-1]-x.index[0]) > pd.Timedelta(window))\n",
    "# df = df[df['run'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's label 'out of map' runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.groupby(\"run\").apply(lambda x: x.assign(out_of_map=\n",
    "#             True if (x[[f\"ground_truth_odom_{a}\" for a in [\"x\",\"y\"]]].iloc[-1].abs() > config.plane_side/2).any()\n",
    "#             else False)).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we are correctly labeling run that end with 'out of map' scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def statistics(df):\n",
    "#     print(f'Unique runs: {len(df[\"run\"].unique())}')\n",
    "#     print(f'Out of map runs: {len(df.groupby(\"run\").filter(lambda x: x[\"out_of_map\"].any())[\"run\"].unique())*100/len(df[\"run\"].unique()):2.0f}%')\n",
    "#     s0, s1, s2 = df[\"obstacle_near\"], df.loc[df[\"out_of_map\"],\"obstacle_near\"], df.loc[~df[\"out_of_map\"],\"obstacle_near\"]\n",
    "#     perc = lambda x: x.astype(int).sum()*100/len(df)\n",
    "#     print(f'Obstacle detection readings - Total: {perc(s0):2.1f}%,\\nOut Of Map scenarios total obstacle readings: {perc(s1):2.1f}%,\\nObstacle scenarios total: {perc(s2):2.1f}%')\n",
    "#     print(f'Average % of obs. detection readings per run: {df[~df[\"out_of_map\"]].groupby(\"run\")[\"obstacle_near\"].apply(lambda x: x.sum()/len(x)).mean()*100:2.2f}%')  \n",
    "# statistics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def setup_topview(ax, fixed=True):\n",
    "    half_side = config.plane_side // 2\n",
    "    bounds = [-half_side - 1, half_side + 1]\n",
    "    if fixed:\n",
    "        ax.set(xlim=bounds, ylim=bounds, autoscale_on=False)\n",
    "        major_ticks = np.arange(-half_side, half_side + 1, 5)\n",
    "        minor_ticks = np.arange(-half_side, half_side + 1, 2.5)\n",
    "        ax.set_xticks(major_ticks)\n",
    "        ax.set_xticks(minor_ticks, minor=True)\n",
    "        ax.set_yticks(major_ticks)\n",
    "        ax.set_yticks(minor_ticks, minor=True)\n",
    "    ax.set(title=\"Top view\", adjustable='box')\n",
    "   \n",
    "    ax.grid(which='both')\n",
    "    ax.grid(which='minor', alpha=0.2)\n",
    "    ax.grid(which='major', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_runs(df, target = 'run'):\n",
    "    fig, ax = plt.subplots(figsize=(5,5), dpi=300)\n",
    "    input_cols = [f'ground_truth_odom_{axis}' for axis in ['x', 'y', 'theta']]\n",
    "    output_cols = ['gt_rel_' + label.rsplit('_', 1)[-1] for label in input_cols]\n",
    "    df = df.copy()\n",
    "    def rotate(p):\n",
    "        angle = -p.iat[0,-1]\n",
    "        R = np.array([[np.cos(angle), -np.sin(angle)],\n",
    "                      [np.sin(angle), np.cos(angle)]])\n",
    "        p[input_cols] = p - p.iloc[0]\n",
    "        p[input_cols[:2]] = np.squeeze((R @ p.loc[:,input_cols[:2]].T).T).values\n",
    "        return p\n",
    "\n",
    "    df[output_cols] = df.groupby(target)[input_cols].progress_apply(rotate)\n",
    "\n",
    "    setup_topview(ax, fixed=False)\n",
    "    def show_proof(run):\n",
    "        x,y,t = run[output_cols].values.T\n",
    "        ax.plot(x,y, linestyle='--',alpha=0.9)\n",
    "        #ax.plot(x[-1:],y[-1:], 'x', color='black', zorder=3)\n",
    "        sns.scatterplot(x=x[-1:],y=y[-1:], style=['x'], alpha=1, color='crimson',s=100, ax=ax, legend=False, zorder=4, markers=['X'])\n",
    "\n",
    "        #sns.lineplot(x=[x[0], x[0]+np.cos(t[0])*2],y=[y[0], y[0]+np.sin(t[0])*2], color='black', ax=ax)\n",
    "    ax.plot([0],[0], 'o', color='black', ms=10, zorder=10)\n",
    "    ax.arrow(0,0,2,0, color='black', head_width=0.3, zorder=10)\n",
    "    df[df[target].isin([1,4,5,8,9, 12])].groupby(target).progress_apply(show_proof)\n",
    "    ax.set_title('Blocks relative to spawn point')\n",
    "    ax.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('relative_travel.png')\n",
    "#     plt.xlim(-12,12)\n",
    "#     plt.ylim(-12,12)\n",
    "\n",
    "\n",
    "plot_relative_runs(df, target='big_block')\n",
    "#reduced = df.groupby('run').apply(lambda x: x.iloc[10:]).reset_index(level=0, drop=True)\n",
    "#plot_relative_runs(reduced, axes[1])\n",
    "\n",
    "\n",
    "#axes[1].set_xlim(-2,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cut the first 10 iteration to be sure we do not include any precedent run data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = reduced\n",
    "# df = df.groupby('run').filter(lambda x: (x.index[-1]-x.index[0]) > pd.Timedelta(window))\n",
    "# statistics(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlliamo la qualità delle run registrate, hanno tutte senso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils_ros\n",
    "from utils_ros import add_arrow\n",
    "from functools import partial\n",
    "importlib.reload(utils_ros)\n",
    "import random\n",
    "random.seed(0)\n",
    "def plot_traces(df, target='run', full=1):\n",
    "    fig, ax = plt.subplots(figsize=(6,6), dpi=300)\n",
    "    interesting = [5,4,1,8,9,12]\n",
    "    setup_topview(ax)\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.7)\n",
    "    colors = [f'C{i}' for i in range(len(interesting))]\n",
    "    random.shuffle(colors)\n",
    "    colors = {i:c for i,c in zip(interesting,colors)}\n",
    "    def f(run):\n",
    "        if run.iloc[0][target]%full != 0:\n",
    "            return\n",
    "        x,y = run[['ground_truth_odom_x','ground_truth_odom_y']].values.T\n",
    "        #print(x.shape, y.shape, x[0], y[0])\n",
    "        ax.plot(x,y, linestyle='--', alpha=0.7, zorder=1, color=colors[run.iloc[0][target]])\n",
    "        add_arrow(ax.lines[-1], x, y, step=100, size=10)\n",
    "\n",
    "        sns.scatterplot(x=x[:1],y=y[:1], style=['x'], alpha=1, color=colors[run.iloc[0][target]], s=100, ax=ax, legend=False, zorder=4)\n",
    "        sns.scatterplot(x=x[-1:],y=y[-1:], style=['x'], alpha=1, color='crimson',s=100, ax=ax, legend=False, zorder=4, markers=['X'])\n",
    "        ax.text(x[-100],y[-100],s=run.iloc[0][target],\n",
    "               horizontalalignment='center', verticalalignment='center', bbox=props,  weight='bold', zorder=5)\n",
    "\n",
    "    \n",
    "    df[df[target].isin(interesting)].groupby(target).progress_apply(f)\n",
    "    #ax.scatter(x=points[:,0], y=points[:,1])\n",
    "    \n",
    "    ax.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('absolute_travel.png')\n",
    "plot_traces(df, 'big_block',full=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import timedelta as td\n",
    "# run_lengths_time = df.groupby('run').apply(lambda x: (x.index[-1] - x.index[0])).sort_values()\n",
    "# run_lengths_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Occupancy Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils_ros import ROBOT_GEOMETRY_FULL, mktransf\n",
    "# fig, ax = plt.subplots(figsize=(8,8))\n",
    "# coords = np.stack(np.meshgrid(\n",
    "#     np.linspace(0, .8, int(.8 / .04)),\n",
    "#     np.linspace(-.4, .4, int(.8 / .04))\n",
    "# )).reshape([2, -1]).T\n",
    "# display(coords.shape)\n",
    "# ax.set_aspect('equal')\n",
    "# sns.scatterplot(x=coords[:,0], y=coords[:,1], ax=ax);\n",
    "# def plot_transform(ax, tr, color='b', length=1, debug=False):\n",
    "#     origin = (tr @ np.array([0, 0, 1]))[:2]\n",
    "#     xhat   = (tr @ np.array([length, 0, 1]))[:2]\n",
    "#     yhat   = (tr @ np.array([0, length/2, 1]))[:2] #(tr @ np.array([0, length, 1]))[:2]\n",
    "\n",
    "#     ax.arrow(*origin, *(xhat - origin), head_width=0.005, color=color, zorder=3)\n",
    "#     ax.arrow(*origin, *(yhat - origin), head_width=0.005, color=color,zorder=3, alpha=1)\n",
    "    \n",
    "# for r in ROBOT_GEOMETRY_FULL:\n",
    "#     plot_transform(ax, r, length=0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import occupancy_map\n",
    "importlib.reload(occupancy_map)\n",
    "from occupancy_map import compute_occupancy_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "importlib.reload(config)\n",
    "from config import SENSORS\n",
    "coords = np.stack(np.meshgrid(\n",
    "    np.linspace(0, .8, int(.8 / .04)),\n",
    "    np.linspace(-.4, .4, int(.8 / .04))\n",
    ")).reshape([2, -1]).T\n",
    "SENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random((400,1, 2))-np.random.random((1,5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby('big_block')['run'].count()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (df.groupby('big_block')['run'].nunique()*df.groupby('big_block')['run'].count()).sort_values()\n",
    "x = x / x.sum()\n",
    "print(x)\n",
    "print(np.random.choice(x.index, p=x, size=3, replace=False))\n",
    "plt.plot(x.index,x.values, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.choice(df['big_block'].unique())\n",
    "run = df[df['big_block'] == 5].iloc[-1900:-1400].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['legend.handlelength'], plt.rcParams['legend.handleheight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([18,7])*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "import occupancy_map\n",
    "importlib.reload(occupancy_map)\n",
    "from occupancy_map import compute_occupancy_map\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.legend_handler import HandlerPatch\n",
    "import matplotlib.colors as clr\n",
    "from matplotlib import rc\n",
    "    \n",
    "def show_occupancy_map(run, target_iteration, dpi, delta, legend=True, indicators=True, only_map=False, title='omap_example'):\n",
    "    \n",
    "    \n",
    "    if only_map:\n",
    "        fig,axs =plt.subplots(1,1, figsize=(9, 3.5), dpi=dpi)\n",
    "        axs = {1:axs}\n",
    "    else:\n",
    "        fig,axs =plt.subplots(1,2, figsize=(9, 3.5), dpi=dpi)\n",
    "        axs[0].imshow(cv_from_binary(run.iloc[target_iteration]['image']))\n",
    "        axs[0].axis('off')\n",
    "        \n",
    "    x, maps = compute_occupancy_map(run.iloc[target_iteration], run, coords, SENSORS, window, delta)\n",
    "    x = x[0].reshape(20,20)\n",
    "    res = np.empty((20, 20, 3), dtype=np.uint8)\n",
    "    res[x == -1] = (190, 190, 190)\n",
    "    res[x == 0] = (0, 255, 0)\n",
    "    res[x == 1] = (255, 0, 0)\n",
    "    #print(x)\n",
    "    axs[1].imshow(res)\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    if indicators:\n",
    "        ratio = 20 / 0.8\n",
    "        for r in scaled_full_robot_geometry(ratio):\n",
    "            plot_transform(axs[1], mktransf((10-0.5, 20-0.5, -np.pi / 2)) @ r, color='black', length=config.max_sensing_distance * ratio, head_width=0.2)\n",
    "\n",
    "        axs[1].plot([10 / 20, 0], [0, 0.5], linewidth=.8, linestyle='--', color='grey', transform=axs[1].transAxes)\n",
    "        axs[1].plot([10 / 20, 1], [0, 0.5], linewidth=.8, linestyle='--', color='grey', transform=axs[1].transAxes)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def make_legend_arrow(legend, orig_handle,\n",
    "                          xdescent, ydescent,\n",
    "                          width, height, fontsize):\n",
    "        p = mpatches.FancyArrow(0, 0.5*height, width, 0, length_includes_head=True, head_width=0.75*height )\n",
    "        return p\n",
    "\n",
    "\n",
    "    class HandlerRect(HandlerPatch):\n",
    "\n",
    "        def create_artists(self, legend, orig_handle,\n",
    "                           xdescent, ydescent, width, height,\n",
    "                           fontsize, trans):\n",
    "\n",
    "            x = width//2-width//3\n",
    "            y = 0\n",
    "            w = h = 10\n",
    "\n",
    "            # create\n",
    "            p = mpatches.Rectangle(xy=(x, y), width=w, height=h)\n",
    "\n",
    "            # update with data from oryginal object\n",
    "            self.update_prop(p, orig_handle, legend)\n",
    "\n",
    "            # move xy to legend\n",
    "            p.set_transform(trans)\n",
    "\n",
    "            return [p]\n",
    "    # #Create legend from custom artist/label lists\n",
    "    # axs[1].legend([handle for i,handle in enumerate(handles) if i in display]+[simArtist,anyArtist],\n",
    "    #           [label for i,label in enumerate(labels) if i in display]+['Simulation', 'Analytic'])\n",
    "    if legend:\n",
    "        #Create custom artists\n",
    "        fov = plt.Line2D((0,1),(0,0), color='grey', linestyle='--')\n",
    "        sensor = plt.arrow(0,0,0,0, color='black')\n",
    "\n",
    "        obst = mpatches.Rectangle((0,0),1,1,facecolor='red')\n",
    "        free = mpatches.Rectangle((0,0),1,1,facecolor='green')\n",
    "        unkn = mpatches.Rectangle((0,0),1,1,facecolor='grey')\n",
    "        axs[1].legend([fov, sensor, obst,free, unkn],['FOV', 'Sensor', 'Obstacle', 'Free Space', 'Unknown'], \n",
    "                      loc='upper left', handler_map={mpatches.FancyArrow : HandlerPatch(patch_func=make_legend_arrow),mpatches.Rectangle: HandlerRect()})\n",
    "\n",
    "    plt.subplots_adjust(0,0,1,1)\n",
    "    fig.tight_layout(pad=0)\n",
    "    plt.savefig(f'{title}.png')\n",
    "    return maps\n",
    "    \n",
    "def naked_omap(maps, dpi):\n",
    "    \n",
    "    rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "    sqrt = int(np.sqrt(len(maps)))\n",
    "    fig, axs = plt.subplots(sqrt,sqrt, figsize=(10,10), dpi=dpi)\n",
    "    axs = np.array(axs).flatten()\n",
    "    v = maps[:sqrt**2]\n",
    "    for i, m in enumerate(v):\n",
    "        x = np.flip(np.rot90(m.reshape(20,20)),axis=1)\n",
    "        res = np.empty((20, 20, 3), dtype=np.uint8)\n",
    "        res[x == -1] = (190, 190, 190)\n",
    "        res[x == 0] = (0, 255, 0)\n",
    "        res[x == 1] = (255, 0, 0)\n",
    "        axs[i].imshow(res)\n",
    "        axs[i].axis('off')\n",
    "        #s=f'$x_{{{i-int(len(v)/2)}}}$'\n",
    "        axs[i].text(0.2,0.80, s=i-int(len(v)/2), color='black', ha=\"center\", va=\"center\", size=20, transform=axs[i].transAxes)\n",
    "        \n",
    "        if i-int(len(v)/2) == 0:\n",
    "            axs[i].patch.set_edgecolor('black')  \n",
    "            axs[i].patch.set_linewidth('5') \n",
    "            axs[i].axis('on')\n",
    "            axs[i].set_xticks([],minor=[])\n",
    "            axs[i].set_yticks([],minor=[])\n",
    "            ratio = 20 / 0.8\n",
    "            for r in scaled_full_robot_geometry(ratio):\n",
    "                plot_transform(axs[i], mktransf((10-0.5, 20-0.5, -np.pi / 2)) @ r, color='black', length=config.max_sensing_distance * ratio, head_width=0.2)\n",
    "\n",
    "    plt.subplots_adjust(0,0,1,1)\n",
    "    fig.tight_layout(pad=0.1)\n",
    "    plt.savefig('omap_before_agg.png')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "run = df[df['big_block'] == 5].iloc[-1900:-1400].copy()\n",
    "\n",
    "dpi = 300\n",
    "maps = show_occupancy_map(run, 47, dpi, delta=0.04, legend=False)\n",
    "#maps2 = show_occupancy_map(run, 47, dpi, delta=0.4, legend=False, indicators=False, only_map=True, title='lower_delta')\n",
    "#maps2 = show_occupancy_map(run, 47, dpi, delta=0.02, legend=False, indicators=False, only_map=True, title='higher_delta')\n",
    "naked_omap(maps[0::4],dpi)\n",
    "#naked_omap(maps2[0::4],dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = '8s'\n",
    "delta = 0.04\n",
    "import occupancy_map\n",
    "importlib.reload(occupancy_map)\n",
    "from occupancy_map import compute_occupancy_map\n",
    "occ_map = run.progress_apply(compute_occupancy_map, axis=1, args=(run, coords, SENSORS, window, delta))\n",
    "if 'target_map' in run.columns:\n",
    "    run['target_map'] = occ_map\n",
    "else:\n",
    "    run = pd.concat([run, occ_map],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import animator\n",
    "import utils\n",
    "# importlib.reload(utils)\n",
    "importlib.reload(animator)\n",
    "save_path = os.path.join(d.path,'single_runs',f'omap_big_block{r}.mp4')\n",
    "animator.Animator(run, targets, rate=30, save_path=save_path, s=slice(-30,None,None),\n",
    "                  extra_info={'Time window':window, ' delta': delta})\n",
    "Video(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks healthy, process the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_map = df.groupby('big_block').progress_apply(lambda x: x.apply(compute_occupancy_map, axis=1, args=(x, coords, SENSORS, window, delta)))\n",
    "if 'target_map' in df.columns:\n",
    "    df['target_map'] = occ_map\n",
    "else:\n",
    "    df = pd.concat([df, occ_map],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = [25,4]\n",
    "test_ids = [26,24]\n",
    "\n",
    "test_df = df[df['big_block'].isin(test_ids)]\n",
    "val_df = df[df['big_block'].isin(val_ids)]\n",
    "train_df = df[df['big_block'].isin(set(df['big_block'].unique())-set(test_ids)-set(val_ids))]\n",
    "len(train_df), len(val_df), len(test_df)\n",
    "train_df.to_pickle(os.path.join(d.path,'train.pkl'))\n",
    "val_df.to_pickle(os.path.join(d.path,'valid.pkl'))\n",
    "test_df.to_pickle(os.path.join(d.path,'test.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(os.path.join(d.path,'dataset.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'runs':df.groupby('big_block')['run'].nunique()**2, 'iterations': df.groupby('big_block')['run'].count()})\n",
    "test['ratio'] = test['runs']**2 / test['iterations']\n",
    "test['p'] = test['ratio'] / test['ratio'].sum()\n",
    "pos = np.random.choice(test.index, p=test['p'], size=len(x), replace=False)\n",
    "test = test.reindex(pos)\n",
    "test['pos'] = np.arange(len(x))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (df.groupby('big_block')['run'].nunique()**2/df.groupby('big_block')['run'].count()).sort_values()\n",
    "\n",
    "ep = np.random.choice(x.index, p=x, size=len(x), replace=False)\n",
    "print(ep)\n",
    "test = pd.DataFrame({'p':x.values}, index=x.index)\n",
    "pd.DataFrame({'p':x.values}, index=x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_ros import quaternion2yaw,scaled_full_robot_geometry\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.imshow(np.rot90(df['target_map'].iloc[0].reshape(20,20)))\n",
    "def plot_transform(ax, tr, color='b', length=1):\n",
    "    origin = (tr @ np.array([0, 0, 1]))[:2]\n",
    "    xhat   = (tr @ np.array([length, 0, 1]))[:2]\n",
    "    yhat   = (tr @ np.array([0, 0, 1]))[:2] #(tr @ np.array([0, length, 1]))[:2]\n",
    "\n",
    "    ax.arrow(*origin, *(xhat - origin), head_width=0.5, color=color,zorder=3, capstyle='projecting')\n",
    "    ax.arrow(*origin, *(yhat - origin), head_width=0.005, color=color,zorder=3, alpha=0.02)\n",
    "\n",
    "ratio = 20/0.8\n",
    "\n",
    "custom = scaled_full_robot_geometry(ratio)\n",
    "    \n",
    "for r in custom:\n",
    "    plot_transform(ax, mktransf((10,20,-np.pi/2))@r, color='red',length=0.12*ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from animator import Animator\n",
    "\n",
    "run = df[df['run'] == 30].copy()\n",
    "save_path = os.path.join(d.path,'single_runs',f'omap_test.mp4')\n",
    "Animator(run, targets, rate=30, save_path=save_path, s=slice(-100,None,None),extra_info={'Time window':window, ' delta': delta})\n",
    "Video(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from utils_ros import scaled_full_robot_geometry, mktransf\n",
    "def compute_map_density(df, title=None):\n",
    "    a = np.array([np.array(x).reshape(20,20) for x in df['target_map'].values])\n",
    "    a[a == 0] = 1\n",
    "    a[a == -1] = 0\n",
    "    b = a.sum(axis=0) / a.shape[0]\n",
    "    fig, ax = plt.subplots(figsize=(5,5),dpi=150)\n",
    "    #ax = sns.heatmap(data=b.reshape(20,20), cbar=True)\n",
    "    im = ax.imshow(b.reshape(20,20))\n",
    "\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(im, ax=ax, cax=cax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('x (forward axis)')\n",
    "    ax.set_ylabel('y', rotation=0, labelpad=10)\n",
    "    ratio = 20 / 0.8\n",
    "    for r in scaled_full_robot_geometry(ratio):\n",
    "        plot_transform(ax, mktransf((10-0.5, 20-0.5, -np.pi / 2)) @ r, color='white', length=config.max_sensing_distance * ratio)\n",
    "\n",
    "    ax.plot([10 / 20, 0], [0, 0.5], linewidth=.8, linestyle='--', color='blue', transform=ax.transAxes)\n",
    "    ax.plot([10 / 20, 1], [0, 0.5], linewidth=.8, linestyle='--', color='blue', transform=ax.transAxes)\n",
    "    ax.set_aspect('equal')\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    plt.subplots_adjust(0,0,1,1)\n",
    "    # plt.savefig()\n",
    "    plt.show()\n",
    "compute_map_density(df, title='Ground truth frequency in dataset (new approach)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['sensor'] == 0.12).value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['out_of_map'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = df.loc[~df['out_of_map'],['run','image','target_map']].reset_index(drop=True).copy()\n",
    "df.to_pickle(os.path.join(d.path, 'dataset.pkl'))\n",
    "#del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from utils import mktransf\n",
    "def plot_last_omap(df, run_id):\n",
    "    if 'target_map' not in df.columns:\n",
    "        print('No occupancy maps')\n",
    "        return\n",
    "    run = df[df['run'] == run_id].copy()\n",
    "    run['gt_pose'] = run[['ground_truth_odom_x', 'ground_truth_odom_y', 'ground_truth_odom_theta']].apply(mktransf, axis=1)\n",
    "\n",
    "    def plot_transform(ax, tr, color='b', length=1, debug=False):\n",
    "        origin = (tr @ np.array([0, 0, 1]))[:2]\n",
    "        xhat   = (tr @ np.array([length, 0, 1]))[:2]\n",
    "        yhat   = (tr @ np.array([0, 0, 1]))[:2] #(tr @ np.array([0, length, 1]))[:2]\n",
    "\n",
    "        ax.arrow(*origin, *(xhat - origin), head_width=0.005, color=color, zorder=3)\n",
    "        ax.arrow(*origin, *(yhat - origin), head_width=0.005, color=color,zorder=3, alpha=0.02)\n",
    "\n",
    "    fix, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "    #fig.tight_layout(w_pad=0.1)\n",
    "    plt.subplots_adjust(top=0.9,wspace=0.1)\n",
    "    \n",
    "    ax = axes[1]\n",
    "    omap = run.iloc[-1]['target_map']\n",
    "    \n",
    "    myColors = ('grey', (0.8, 0.0, 0.0, 1.0), (0.0, 0.8, 0.0, 1.0))\n",
    "    cmap = LinearSegmentedColormap.from_list('Custom', myColors, len(myColors))\n",
    "    sns.heatmap(data=omap.reshape(20,20), ax=ax, cmap=cmap, linecolor='lightgray')\n",
    "    colorbar = ax.collections[0].colorbar\n",
    "    colorbar.set_ticks([-0.667, 0, 0.667])\n",
    "    colorbar.set_ticklabels(['unknown', 'obstacle', 'no obstacle'])\n",
    "    \n",
    "    ax.arrow(0.1,0.5, 0, 0.3, color='white', head_width=0.02, transform=ax.transAxes)\n",
    "    ax.arrow(0.1,0.5, 0.3, 0, color='white', head_width=0.02, transform=ax.transAxes)\n",
    "\n",
    "    #ax.arrow(0,0, , head_width=0.005, color=color,zorder=3, alpha=0.02)\n",
    "    ax.set_title('Last occupancy map')\n",
    "    ax.axis('off')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    ax = axes[0]\n",
    "    #setup_topview(ax)\n",
    "    for a in run['gt_pose'].values[-100::1]:\n",
    "        plot_transform(ax, a, color='b',length=0.10)\n",
    "    ax.set_title('Top view of poses')\n",
    "    \n",
    "    x,y = run[['ground_truth_odom_x','ground_truth_odom_y']].values.T\n",
    "    sns.lineplot(x=x[-20:],y=y[-20:], linestyle='--', alpha=0.8, color='grey', ax=ax, zorder=1)\n",
    "    #add_arrow(ax.lines[-1], x[-20:], y[-20:], step=200)\n",
    "\n",
    "    #sns.scatterplot(x=x[:1],y=y[:1], style=['x'], alpha=1, color='crimson', ax=ax, legend=False, zorder=2, s=200, label='Start')\n",
    "    x_last,y_last=x[-1:],y[-1:]\n",
    "    sns.scatterplot(x=x[-1:],y=y[-1:], style=['x'], alpha=1, color='crimson', ax=ax, legend=False, zorder=4, markers=['X'], s=200, label='Stop')\n",
    "    \n",
    "    obst = points[scipy.spatial.distance.cdist( points, np.array([x_last, y_last]).T ).argmin()]\n",
    "    #ax.scatter(x=obst[0], y=obst[1], s=200, color='crimson')\n",
    "    \n",
    "    ax.add_artist(plt.Circle(obst, radius=0.08, facecolor='red', linestyle='--', alpha=0.5))\n",
    "    ax.add_artist(plt.Circle(obst, radius=0.3, facecolor='none', edgecolor='black', linestyle='--', alpha=0.5))\n",
    "    ax.add_artist(plt.Circle(obst, radius=0.1, facecolor='none', edgecolor='black', linestyle='--'))\n",
    "\n",
    "    extent = 0.3\n",
    "    #ax.set_xlim(x_last[0]-extent,x_last[0]+extent)\n",
    "    ax.set_xlim(ax.get_xlim()[0]-extent, ax.get_xlim()[1]+extent)\n",
    "    ax.set_ylim(y_last[0]-extent,y_last[0]+extent)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    #plt.autoscale(enable=True, axis='both', tight=None)\n",
    "    plt.suptitle(f'Final part of run #{run_id}')\n",
    "    \n",
    "plot_last_omap(run_id=119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "n = 16\n",
    "subset = np.random.choice(df['run'].unique(),n)\n",
    "plt.close()\n",
    "fig, axs = plt.subplots(4,4, figsize=(10,10))\n",
    "run_axs = {s:ax for s, ax in zip(subset, np.array(axs).flatten())}\n",
    "target_runs = df[df['run'].isin(subset) & df['meaningful_omap'].any()]# & df['meaningful_omap'].any() & ()]\n",
    "def plotter(x):\n",
    "    run_id = x.iloc[0]['run']\n",
    "    ax = run_axs[run_id]\n",
    "    omap = x.loc[x['meaningful_omap'][::-1].idxmax(),'target_map']\n",
    "    sns.heatmap(data=omap.reshape(20,20), ax=ax, cbar=False)\n",
    "\n",
    "    ax.axis('off'), ax.get_xaxis().set_visible(False), ax.get_yaxis().set_visible(False)\n",
    "    ax.add_patch(patches.Rectangle((0.,0.),1,1, linewidth=5, edgecolor='white', facecolor='none', transform=ax.transAxes))\n",
    "    ax.text(0.5,0.1, s=str(run_id), transform=ax.transAxes, weight='bold', color='white', size=15, horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "target_runs.groupby('run').apply(plotter)\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "import numpy as np\n",
    "fig = plt.figure(figsize=(10,7.5))\n",
    "gs = matplotlib.gridspec.GridSpec(1, 2, width_ratios=[20,1], height_ratios=[1])\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "## data\n",
    "xx = np.linspace(1,100,num=100) + 20 * np.random.normal(0,1,100)\n",
    "yy = np.linspace(1,100,num=100) + 10 * np.random.normal(0,1,100)\n",
    "\n",
    "## scatter\n",
    "sc = ax.scatter(xx, yy, s=250, alpha=0.35, zorder=100)\n",
    "ax.plot(np.linspace(-100,200,301), np.linspace(-100,200,301),)\n",
    "ax.set_xlim((0, 100))\n",
    "ax.set_ylim((0, 100))\n",
    "ax.grid(linestyle=\"--\", zorder=10)\n",
    "\n",
    "## zoom\n",
    "axins = zoomed_inset_axes(ax, 2, loc=\"upper left\")\n",
    "scins = axins.scatter(xx, yy, s=100, alpha=0.35, zorder=50, marker=\".\", c=\"red\")\n",
    "axins.plot(np.linspace(-100,200,301), np.linspace(-100,200,301), c=\"red\")\n",
    "axins.set_xlim((70, 90))\n",
    "axins.set_ylim((70, 90))\n",
    "mark_inset(ax, axins, loc1=1, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "axins.grid(linestyle=\"--\", zorder=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data=df.groupby('run').apply(lambda x: x['sensor'].astype(int).sum()*100/len(x)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f(x):\n",
    "#     x = x[5:]\n",
    "#     multiplier = 2.\n",
    "#     coeff = (x.index[-1]-x.index[0]).nanoseconds/len(x)\n",
    "#     diff = x['ground_truth_odom_theta'].diff() * coeff\n",
    "#     mask = diff.fillna(0).between(-0.1, 0.1)\n",
    "    \n",
    "#     blocks = (mask.shift() != mask).cumsum().astype(int)\n",
    "#     #assert(blocks.value_counts()\n",
    "    \n",
    "#     x['rotating'] = False\n",
    "#     if len(blocks.unique()) >= 2:\n",
    "#         x.loc[(blocks == 2).idxmax():, 'rotating'] = True\n",
    "#     return x\n",
    "# df2 = df.groupby('run').apply(f).reset_index(level=0,drop=True)\n",
    "# statistics(df2)\n",
    "# df2 = df2.groupby('run').apply(lambda x: x.assign(out_of_map=True if x['rotating'].any() else False))\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze theta instead\n",
    "# df = df.groupby('run').apply(lambda x: x.assign(out_of_map=True if x['sensor'].astype(int).sum() == 0 else False)).reset_index(level=0, drop=True)\n",
    "# print(f'% of runs that ended out of map: {len(df.groupby(\"run\").filter(lambda x: x.iloc[0][\"out_of_map\"])[\"run\"].unique())*100/len(df[\"run\"].unique()):2.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of sensor readings per run, normalized over run length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time analysis - How long does a run usually last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "today = dt.today().replace(hour=0,minute=0,second=0, microsecond=0)\n",
    "fig, ax = plt.subplots(figsize=(35,2))\n",
    "def test(x):\n",
    "    x = x.copy()\n",
    "    x.index -= x.index[0] - today\n",
    "    sns.lineplot(data=x, alpha=0.3, ax=ax)\n",
    "    sns.scatterplot(data=x.iloc[-1:], color=ax.lines[-1].get_color(), ax=ax)\n",
    "    \n",
    "df.groupby('run')['sensor'].apply(test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lengths_iter = df.groupby('run')['x'].count().sort_values()\n",
    "run_lengths_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nanoseconds per iteration on every run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('run').apply(lambda x: (x.index[-1] - x.index[0])/len(x)).sort_values().dt.nanoseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs sorted by biggest timestamp diff on adjacent iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time_diff = df.groupby('run').apply(lambda x: np.diff(x.index).max()).sort_values()\n",
    "run_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shouldn't it be 38 seconds? Why the hiccup at the end?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# longest_run = 79\n",
    "# show_camera_feed(df, run_id=longest_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiccup analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm = np.linalg.norm(df[df['run'] == longest_run][['ground_truth_odom_x','ground_truth_odom_y']].values, axis=1)\n",
    "# display(np.diff(norm).max())\n",
    "# sns.lineplot(data=norm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find those hiccups and fix them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# def clean_runs_median(multiplier, x):\n",
    "#     x = x[1:]\n",
    "#     norm = pd.Series(np.linalg.norm(x[['ground_truth_odom_x','ground_truth_odom_y']].values, axis=1), index=x.index)\n",
    "#     diff = norm.diff()\n",
    "#     med = diff.median()\n",
    "#     MAD = (med - diff.fillna(med)).abs().median()\n",
    "#     mask = diff.between(med-MAD*multiplier, med+MAD*multiplier)\n",
    "#     #return pd.DataFrame({'run':x['run'], 'diff':diff,'mask': mask, 'sensor': x['sensor'], 'med':med,  'mad':mad}, index=x.index)\n",
    "#     if (~mask).any():\n",
    "#         blocks = (mask.shift() != mask).cumsum().astype(int)\n",
    "#         if len(blocks[mask]) > 0:\n",
    "#             shrinked = x[blocks == blocks[mask].value_counts().idxmax()]\n",
    "#             if len(shrinked) > config.window_size:\n",
    "#                 return shrinked\n",
    "#     else:\n",
    "#         return x\n",
    "\n",
    "# test = df.groupby('run').apply(lambda x: x.iloc[3:]).reset_index(level=0, drop=True).groupby('run').apply(partial(clean_runs_median, 3.)).reset_index(level=0, drop=True)\n",
    "# statistics(test)\n",
    "# random_run_id = np.random.choice(test['run'].unique())\n",
    "# test.loc[test['run'] == 79].tail(30)#319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_camera_feed(test, run_id=319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df[df['run'] == 79].iloc[1:].copy()\n",
    "# multiplier = 3.\n",
    "# display(len(x))\n",
    "# norm = pd.Series(np.linalg.norm(x[['ground_truth_odom_x','ground_truth_odom_y']].values, axis=1), index=x.index)\n",
    "# diff = norm.diff()\n",
    "# med = diff.median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAD = (med - diff.fillna(med)).abs().median()\n",
    "# mask = diff.between(med-MAD*multiplier, med+MAD*multiplier)\n",
    "# result = None\n",
    "# if (~mask).any():\n",
    "#     blocks = (mask.shift() != mask).cumsum().astype(int)\n",
    "#     if len(blocks[mask]) > 0:\n",
    "#         shrinked = x[blocks == blocks[mask].value_counts().idxmax()]\n",
    "#         if len(shrinked) > config.window_size:\n",
    "#             result = shrinked\n",
    "# else:\n",
    "#     result = x\n",
    "# display(len(result))\n",
    "# show_camera_feed(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Exclude the still moments after finding an obstacle (mark them as safe)\n",
    "# #diff_mask = diff.abs() > still_threshold\n",
    "# med = diff.median()#diff[diff_mask].iloc[1:].median()\n",
    "# #diff[~diff_mask] = med\n",
    "\n",
    "# # Absolute median deviation\n",
    "# mad = (med - diff.fillna(med)).abs().median()\n",
    "\n",
    "# mask = diff.between(med-mad*multiplier, med+mad*multiplier)\n",
    "# mask.iloc[0] = mask.iloc[1]\n",
    "# return pd.DataFrame({'run':x['run'], 'diff':diff,'mask': mask, 'sensor': x['sensor'], 'med':med,  'mad':mad}, index=x.index)\n",
    "# if (~mask).any():\n",
    "#     blocks = (mask.shift() != mask).cumsum().astype(int)\n",
    "#     if len(blocks[mask]) > 0:\n",
    "#         shrinked = x[blocks == blocks[mask].value_counts().idxmax()]\n",
    "#         if len(shrinked) > config.window_size:\n",
    "#             return shrinked\n",
    "# else:\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_run_id = np.random.choice(test['run'].unique())\n",
    "# print(f'Average % of positive sensor readings per run: {df.groupby(\"run\")[\"sensor\"].apply(lambda x: x.sum()/len(x)).mean()*100:2.2f}%')\n",
    "\n",
    "#show_camera_feed(test, 119)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes = []\n",
    "# r = np.arange(0,60)/10\n",
    "# for m in r:\n",
    "#     a = df.groupby('run').apply(partial(clean_runs_median,'ground_truth_odom_x', m)).reset_index(drop=True)\n",
    "#     if len(a)>0:\n",
    "#         sizes.append(a.groupby('run')['run'].count().sum())\n",
    "#     else:\n",
    "#         sizes.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax = sns.lineplot(x=r,y=sizes, ax=ax)\n",
    "# ax = sns.scatterplot(x=r,y=sizes, ax=ax)\n",
    "# ax.set_xlabel('+-MAD multiplier')\n",
    "# ax.set_ylabel('Dataset lenght after filtering');\n",
    "# ax.set_title('Median absolute deviation')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_runs_std(label, multiplier, x):\n",
    "    diff = x[label].diff()\n",
    "    avg,std = diff.mean(), diff.std()\n",
    "    mask = diff.fillna(avg).between(avg-std*multiplier,avg+std*multiplier)\n",
    "    if (~mask).any():\n",
    "        blocks = (mask.shift() != mask).cumsum().astype(int)\n",
    "        shrinked = x[blocks == blocks[mask].value_counts().idxmax()]\n",
    "        if len(shrinked) > config.window_size:\n",
    "            return shrinked\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "r = np.arange(0,60)/10\n",
    "for m in r:\n",
    "    a = df.groupby('run').apply(partial(clean_runs_std,'ground_truth_odom_y', m)).reset_index(drop=True)\n",
    "    if len(a)>0:\n",
    "        sizes.append(a.groupby('run')['run'].count().sum())\n",
    "    else:\n",
    "        sizes.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.lineplot(x=r,y=sizes, ax=ax)\n",
    "ax = sns.scatterplot(x=r,y=sizes, ax=ax)\n",
    "ax.set_xlabel('+-STD multiplier')\n",
    "ax.set_ylabel('Dataset lenght after filtering');\n",
    "ax.set_title('Standard deviation')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median absolute deviation proves to be a better selector for cleaning the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('run').apply(partial(clean_runs_median,'ground_truth_odom_x', 2.0)).reset_index(level=0,drop=True)\n",
    "df = df.groupby('run').apply(partial(clean_runs_median,'ground_truth_odom_y', 2.0)).reset_index(level=0,drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.linalg.norm(df[df['run'] == 295][['ground_truth_odom_x','ground_truth_odom_y']].values, axis=1)\n",
    "display(np.diff(norm).max())\n",
    "sns.lineplot(data=norm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From 0 to 100% of every run, where does the sensor usually activate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect it to activate towards the end of every run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_run_length = df.groupby('run')['run'].value_counts().min()\n",
    "min_run_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearly_resize(x, resize_window):\n",
    "    step = (len(x)-1)/(resize_window-1)\n",
    "    step_indices = np.around(np.cumsum([0]+[step]*resize_window)[:-1]).astype(int)\n",
    "    return x[step_indices]\n",
    "linearly_resize(np.arange(100),22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( figsize=(25,3))\n",
    "array = np.array([np.array(x) for x in df.groupby('run')['sensor'].apply(lambda x: linearly_resize(x.values, min_run_length)).values])\n",
    "sns.lineplot(data=array.sum(axis=0), ax=ax, label='sum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would it activate before than the end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations before end investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = df.groupby('run').filter(lambda x: x['sensor'].iloc[:int(len(x)*0.5)].any())\n",
    "random_run_id = np.random.choice(check['run'].unique())\n",
    "show_camera_feed(df, random_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many iterations per run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( figsize=(20,5))\n",
    "sns.histplot(data=df.groupby('run').apply(lambda x: len(x)), bins=100, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = random.choice(df['run'].unique())\n",
    "show_camera_feed(run_id=run_id, folder=d.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sensor readings per run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df.groupby('run').apply(lambda x:x.loc[x['out_of_map'],'sensor'].sum()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case_study_run = df.groupby('run').apply(lambda x: x['sensor'].sum()).idxmax()\n",
    "# case_study = df[df['run']==case_study_run].reset_index()\n",
    "# print(f'Best run ({case_study[\"sensor\"].astype(int).sum()} active out of {len(case_study)}): {case_study_run}, taking last 100 iteration before last positive sensor reading')\n",
    "# last_sensor_read = case_study['sensor'][::-1].idxmax()\n",
    "# case_study = case_study.iloc[last_sensor_read-200:last_sensor_read]\n",
    "# case_study['sensor'].astype(int).plot(marker='o',figsize=(20,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import mktransf\n",
    "import analyzer\n",
    "importlib.reload(analyzer)\n",
    "from analyzer import add_occupancy_maps\n",
    "\n",
    "df['occupancy_map'] = add_occupancy_maps(df, window_size=config.window_size, empty_value=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['meaningful_omap'] = df['occupancy_map'].apply(lambda x: x[0] != -2)\n",
    "df['meaningful_omap'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove runs without a single meaningful occ. maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('run').filter(lambda x: x['meaningful_omap'].astype(int).sum() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the poses computed correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mirko omap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.array([np.array(x) for x in run['target_map'].values]), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf(f'{d.path}/unified.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['out_of_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def heatmap_animation(run_id):\n",
    "    images = df.loc[(df['run'] == run_id) & (~df['occupancy_map'].isna()),'occupancy_map'].values\n",
    "    images = np.array([np.array(x) for x in images]).reshape(-1,20,20)[:10]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2 figsize = (12, 8))\n",
    "    ax.axis('off')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    feed_frame = feed_frame = ax[1].imshow(images[0])\n",
    "    x,y = run[['ground_truth_odom_x','ground_truth_odom_y']].values.T\n",
    "    \n",
    "    def init():\n",
    "        feed_frame.set_data(images[0])\n",
    "        return feed_frame,\n",
    "    def animate(i):\n",
    "        feed_frame.set_data(images[i])\n",
    "        return feed_frame,\n",
    "\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "\n",
    "    #grid_kws = {'width_ratios': (0.9, 0.05), 'wspace': 0.2}\n",
    "    plt.close()\n",
    "    return FuncAnimation(fig = fig, func = animate, init_func=init, frames = len(images), interval = 50, blit = False)\n",
    "\n",
    "heatmap_animation(run_id=119)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the last occupancy map look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_camera_plot(ax):\n",
    "    ax.axis('off')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "def show_camera_feed(run_id, folder=None, rate=30):\n",
    "    data = df[df['run'] == run_id]['occupancy_map']\n",
    "    if len(data) == 0:\n",
    "        return\n",
    "    Writer = animation.writers['ffmpeg']\n",
    "    writer = Writer(fps=rate, metadata=dict(artist='Me'), bitrate=1800)\n",
    "    images = data.map(cv_from_binary).map(Image.fromarray, \"RGB\").values\n",
    "    \n",
    "    matplotlib.rcParams['animation.embed_limit'] = images.nbytes * 13215\n",
    "    frac = Fraction(*config.camera_shape[:2][::-1])\n",
    "    fig, ax = plt.subplots(figsize=(frac.numerator*2,frac.denominator*2))\n",
    "    adjust_camera_plot(ax)\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "    feed_frame = ax.imshow(images[0])\n",
    "    def init():\n",
    "        feed_frame.set_data(images[0])\n",
    "        return feed_frame,\n",
    "    def animate(i):\n",
    "        feed_frame.set_data(images[i])\n",
    "        return feed_frame,\n",
    "    ani = FuncAnimation(fig, animate, frames=len(images), interval=1000. / rate, blit=True, init_func=init, repeat=True)\n",
    "    plt.close()\n",
    "    \n",
    "    if folder is None:\n",
    "        folder = '.'\n",
    "    folder = os.path.join(folder, 'single_runs')\n",
    "    pathlib.Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    file_path = os.path.join(folder,f'run_{str(run_id).zfill(3)}.mp4')\n",
    "    ani.save(file_path, writer=writer, progress_callback=lambda i, n: print(f'\\rProgress: {(i+1) * 100. / n:.2f} %', end=''))\n",
    "    print(f'\\rComplete! Video file saved to {file_path}')\n",
    "    return Video(file_path)\n",
    "run_id = 119#random.choice(df['run'].unique())\n",
    "show_camera_feed(run_id=run_id, folder=d.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "setup_topview(ax)\n",
    "x,y = run[['ground_truth_odom_x','ground_truth_odom_y']].values.T\n",
    "sns.lineplot(x=x,y=y, linestyle='--', alpha=0.8, color='grey', ax=ax, zorder=1)\n",
    "add_arrow(ax.lines[-1], x, y, step=100)\n",
    "sns.scatterplot(x=x[:1],y=y[:1], style=['x'], alpha=1, color='crimson', ax=ax, legend=False, zorder=4)\n",
    "sns.scatterplot(x=x[-1:],y=y[-1:], style=['x'], alpha=1, color='crimson', ax=ax, legend=False, zorder=4, markers=['X'])\n",
    "ax.text(x[int(len(x)*0.5)],y[int(len(y)*0.5)],s=run.iloc[0]['run'],\n",
    "        horizontalalignment='center', verticalalignment='center', bbox=props,  weight='bold', zorder=5)\n",
    "ax.scatter(x=points[:,0], y=points[:,1])\n",
    "ax.set_xlim(min(x)+.2, max(x)+.2)\n",
    "ax.set_ylim(min(y)+.2, max(y)+.2)\n",
    "ax.set_aspect('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyzer import Animator\n",
    "save_path = os.path.join(d.path,'single_runs',f'omap_{random_run}.mp4')\n",
    "Animator(run, targets, rate=30, frames=None, save_path=save_path)\n",
    "Video(save_path)\n",
    "# TODO animator with relative poses and translated point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyzer import reset_odom_run\n",
    "instructions = {'translation': [('ground_truth_odom_x', 'x'),\n",
    "                                ('ground_truth_odom_y', 'y')],\n",
    "                'rotation': ('ground_truth_odom_theta', 'theta')}\n",
    "df2 = reset_odom_run(df, instructions)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_run = np.random.choice(df['run'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df[df['run'] == random_run]\n",
    "df_check['sensor'].astype(int).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about odometry?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's build the ideal odometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['ground_truth_odom_x', 'ground_truth_odom_y', 'ground_truth_odom_theta']\n",
    "output_cols = ['gt_rel_' + label.rsplit('_', 1)[-1] for label in input_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = len(df)\n",
    "before, len(df.groupby('run').filter(lambda x: x.iloc[-1][output_cols[0]] > 0) or x.iloc[-1][output_cols[1]].between(-2,2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A practical way to discard buggy runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after = len(df)\n",
    "print(f'{before-after} iterations have been removed, reason: buggy runs ({before} -> {after})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitced92ccf11974e4aa6fb451ffa2652ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
